{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "(118, 320, 480, 1)\n",
      "(118, 320, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Dropout, merge\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.optimizers import *\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import concatenate,Conv2DTranspose\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "K.set_image_dim_ordering('tf')\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "train = np.load('/home/shubham/Documents/CrackForest-dataset-master/train.npy')\n",
    "labels = np.load('/home/shubham/Documents/CrackForest-dataset-master/labelsBound.npy')\n",
    "#labels = to_categorical(labels)\n",
    "labels = labels.reshape(labels.shape[0],320,480,1)\n",
    "print np.unique(labels)\n",
    "#labels = to_categorical(y=labels,n)\n",
    "import tensorflow as tf\n",
    "print labels.shape\n",
    "print train.shape\n",
    "smooth = 1.\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=1)\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice(y_true, y_pred):\n",
    "    return -(binary_crossentropy(y_true, y_pred)+(dice_coef(y_true, y_pred)))\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "inputs = Input((320,480,3))\n",
    "x = Conv2D(filters=32,activation='relu',dilation_rate=(1,1),kernel_size=(3,3),padding='same')(inputs)\n",
    "x = Conv2D(filters=32,activation='relu',dilation_rate=(1,1),kernel_size=(3,3),padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=64,activation='relu',dilation_rate=(2,2),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=64,activation='relu',dilation_rate=(2,2),kernel_size=(3,3),padding='same')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(3,3),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(3,3),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(3,3),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(3,3),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(2,2),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(2,2),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same',kernel_initializer='he_normal')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(1,1),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2D(filters=128,activation='relu',dilation_rate=(1,1),kernel_size=(3,3),padding='same')(x)\n",
    "x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same',kernel_initializer='he_normal')(x)\n",
    "x = Conv2D(filters=32,activation='relu',dilation_rate=(3,3),kernel_size=(7,7),padding='same')(x)\n",
    "x = Conv2D(filters=32,activation='relu',dilation_rate=(1,1),kernel_size=(1,1),padding='same')(x)\n",
    "x = Conv2D(filters=1,activation='sigmoid',kernel_size=(1,1),padding='same')(x)\n",
    "\n",
    "model = Model(inputs=inputs,outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 320, 480, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 320, 480, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 320, 480, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 160, 240, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 160, 240, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 160, 240, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 80, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 80, 120, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 80, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 80, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 80, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 80, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 80, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 160, 240, 128)     65664     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 160, 240, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 160, 240, 128)     147584    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 320, 480, 64)      32832     \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 320, 480, 32)      100384    \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 320, 480, 32)      1056      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 320, 480, 1)       33        \n",
      "=================================================================\n",
      "Total params: 1,372,481\n",
      "Trainable params: 1,372,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-5,decay=1e-6), loss=bce_dice, metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/miniconda2/lib/python2.7/site-packages/keras/preprocessing/image.py:594: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/shubham/miniconda2/lib/python2.7/site-packages/keras/preprocessing/image.py:602: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/100 [===>..........................] - ETA: 2:37 - loss: -0.7131 - dice_coef: 0.0193"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='/home/shubham/Documents/CrackForest-dataset-master/mynet1.h5',\n",
    "                             monitor='val_loss',verbose=1,save_best_only=True)\n",
    "#model.load_weights('/home/shubham/Documents/CrackForest-dataset-master/mynet.h5')\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     zoom_range=0.2,shear_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(train, augment=True, seed=seed)\n",
    "\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_datagen.flow(x=train[:100],batch_size=1,seed=1), mask_datagen.flow(x=labels[:100],batch_size=1,seed=1))\n",
    "valid_generator = zip(image_datagen.flow(x=train[100:],batch_size=1,seed=1), mask_datagen.flow(x=labels[100:],batch_size=1,seed=1))\n",
    "model.fit_generator(callbacks=[checkpoint],validation_data=valid_generator,validation_steps=40,\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('/home/shubham/Documents/CrackForest-dataset-master/seg/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = img/255.\n",
    "img = (img-np.mean(img))/np.std(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.reshape(1,320,480,3)\n",
    "out = model.predict(img)\n",
    "print out.shape\n",
    "out = out.transpose([0,3,1,2])\n",
    "io.imshow(out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('/home/shubham/Documents/CrackForest-dataset-master/mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
